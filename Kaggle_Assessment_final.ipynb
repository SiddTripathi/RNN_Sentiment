{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "#from sentiment_utils import *\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk.corpus import stopwords\n",
    "np.random.seed(1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from emo_utils import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(input_text):\n",
    "    '''\n",
    "    Function to remove English stopwords from a Pandas Series.\n",
    "    \n",
    "    Parameters:\n",
    "        input_text : text to clean\n",
    "    Output:\n",
    "        cleaned Pandas Series \n",
    "    '''\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = input_text.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "def remove_mentions(input_text):\n",
    "    '''\n",
    "    Function to remove mentions, preceded by @, in a Pandas Series\n",
    "    \n",
    "    Parameters:\n",
    "        input_text : text to clean\n",
    "    Output:\n",
    "        cleaned Pandas Series \n",
    "    '''\n",
    "    return re.sub(r'@\\w+', '', input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1                I`d have responded, if I were going   neutral\n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2  088c60f138                          my boss is bullying me...  negative\n",
       "3  9642c003ef                     what interview! leave me alone  negative\n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...  negative"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\Siddharth Tripathi\\Desktop\\DataScience_Pranjal\\Kaggle_assessment\\sentiment-analysis-msa-phase-2\\train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mood = train_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mood Distribution')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = [1,2,3]\n",
    "plt.bar(index,Mood,color=['r','b','g'])\n",
    "plt.xticks(index,['Negative','Neutral','Positive'])\n",
    "plt.xlabel('Mood')\n",
    "plt.ylabel('Mood Count')\n",
    "plt.title('Mood Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID       object\n",
       "text         object\n",
       "sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                I`d have responded, if I were going          1\n",
       "1      Sooo SAD I will miss you here in San Diego!!!          0\n",
       "2                          my boss is bullying me...          0\n",
       "3                     what interview! leave me alone          0\n",
       "4   Sons of ****, why couldn`t they put them on t...          0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['text', 'sentiment']]\n",
    "train_df.text = train_df.text.apply(str)\n",
    "train_df.text = train_df.text.apply(remove_mentions)\n",
    "train_df.loc[:,'sentiment'] = train_df.sentiment.map({'negative':0,'neutral':1,'positive':2})\n",
    "#train_df = train_df.drop(['airline_sentiment'], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs_train = train_df[\"text\"].values\n",
    "sentiment_train = train_df['sentiment'].values\n",
    "\n",
    "maxLen = len(max(raw_docs_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train data samples: (24732,)\n",
      "# Test data samples: (2749,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(raw_docs_train, sentiment_train, \n",
    "                                                  stratify=sentiment_train, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)\n",
    "print('# Train data samples:', X_train.shape)\n",
    "print('# Test data samples:', X_test.shape)\n",
    "assert X_train.shape[0] == Y_train.shape[0]\n",
    "assert X_test.shape[0] == Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24732, 3)\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(np.unique(sentiment_train))\n",
    "Y_oh_train = np_utils.to_categorical(Y_train, num_labels)\n",
    "Y_oh_test = np_utils.to_categorical(Y_test, num_labels)\n",
    "print(Y_oh_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(r'C:\\Users\\Siddharth Tripathi\\Desktop\\DataScience_Pranjal\\Kaggle_assessment\\sentiment-analysis-msa-phase-2\\glove.6B\\glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words =[word.lower().replace('\\t', '') for word in X[i].split(' ') if word.replace('\\t', '') != '']\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            try:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            except: 0\n",
    "            # Increment j to j + 1\n",
    "            j = j+1\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras Embedding layer\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltsm_model(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the ltsm_model model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    sentence_indices =  Input(shape=input_shape, dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(3, activation=None)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=[sentence_indices], outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 29, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 29, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,669\n",
      "Trainable params: 223,619\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ltsm_model((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24732, 29)\n"
     ]
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "print(X_train_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24732 samples, validate on 2749 samples\n",
      "Epoch 1/20\n",
      "24732/24732 [==============================] - 212s 9ms/step - loss: 0.9404 - accuracy: 0.5566 - val_loss: 0.8605 - val_accuracy: 0.6402\n",
      "Epoch 2/20\n",
      "24732/24732 [==============================] - 206s 8ms/step - loss: 0.8376 - accuracy: 0.6359 - val_loss: 0.8369 - val_accuracy: 0.6424\n",
      "Epoch 3/20\n",
      "24732/24732 [==============================] - 200s 8ms/step - loss: 0.7984 - accuracy: 0.6590 - val_loss: 0.8050 - val_accuracy: 0.6548\n",
      "Epoch 4/20\n",
      "24732/24732 [==============================] - 201s 8ms/step - loss: 0.7677 - accuracy: 0.6764 - val_loss: 0.7702 - val_accuracy: 0.6704\n",
      "Epoch 5/20\n",
      "24732/24732 [==============================] - 197s 8ms/step - loss: 0.7365 - accuracy: 0.6905 - val_loss: 0.8828 - val_accuracy: 0.5973\n",
      "Epoch 6/20\n",
      "24732/24732 [==============================] - 197s 8ms/step - loss: 0.7083 - accuracy: 0.7056 - val_loss: 0.7747 - val_accuracy: 0.6672\n",
      "Epoch 7/20\n",
      "24732/24732 [==============================] - 197s 8ms/step - loss: 0.6753 - accuracy: 0.7228 - val_loss: 0.7774 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b49a9bcd30>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(X_train_indices, y=Y_oh_train, batch_size=5, epochs=20, \n",
    "          verbose=1, validation_data=(X_test_indices, Y_oh_test), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last session of the day  http://twitpic.com/67ezh 1\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['Last session of the day  http://twitpic.com/67ezh'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  str(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1 = pd.read_csv(r\"C:\\Users\\Siddharth Tripathi\\Desktop\\DataScience_Pranjal\\Kaggle_assessment\\sentiment-analysis-msa-phase-2\\test.csv\")\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.text = train_df1.text.apply(str)\n",
    "train_df1.text = train_df1.text.apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "raw_docs_train1 = train_df1[\"text\"].values\n",
    "maxLen1 = len(max(raw_docs_train1, key=len).split())\n",
    "print(maxLen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices1 = sentences_to_indices(raw_docs_train1, word_to_index, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 29)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.6936086e-02, 8.3215010e-01, 8.0913760e-02],\n",
       "       [1.6314657e-03, 1.0326652e-02, 9.8804188e-01],\n",
       "       [9.9129796e-01, 8.1022503e-03, 5.9983617e-04],\n",
       "       ...,\n",
       "       [5.8848321e-01, 3.6583227e-01, 4.5684539e-02],\n",
       "       [7.6659261e-03, 4.7881305e-02, 9.4445282e-01],\n",
       "       [1.1322093e-02, 2.7289104e-01, 7.1578681e-01]], dtype=float32)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train_indices1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_arr=model.predict(X_train_indices1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(my_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in final:\n",
    "pred=[]\n",
    "for x in my_arr:\n",
    "    pred.append(list(x).index(x.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 2, 2, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 2, 0, 0, 0, 2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 1, 0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 0, 2, 2, 0, 1, 2, 1, 1, 1, 0, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 2, 2, 1, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 1, 0, 2, 0, 0, 1, 1, 1, 0, 0, 2, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 2, 1, 1, 1, 2, 0, 2, 1, 0, 0, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 2, 0, 2, 1, 1, 2, 2, 1, 1, 2, 0, 0, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 0, 0, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 0, 2, 0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 0, 0, 2, 1, 1, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 2, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 2, 2, 2, 1, 0, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 0, 2, 1, 0, 1, 2, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 2, 1, 2, 2, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1, 2, 1, 0, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 2, 2, 0, 2, 2, 2, 0, 0, 1, 0, 0, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 0, 1, 1, 1, 2, 2, 0, 1, 1, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0, 2, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 0, 1, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 2, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 0, 2, 1, 0, 0, 1, 0, 2, 2, 2, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 2, 1, 0, 2, 2, 1, 0, 2, 2, 2, 2, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 0, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 1, 1, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 2, 1, 0, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 2, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 0, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 1, 0, 1, 0, 1, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 2, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 1, 0, 1, 0, 2, 2, 2, 0, 1, 1, 2, 1, 1, 0, 1, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 2, 0, 1, 2, 2, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 2, 2, 1, 2, 0, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 2, 0, 0, 2, 1, 0, 1, 2, 2, 1, 2, 1, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 0, 1, 1, 2, 0, 2, 0, 0, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 1, 1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 1, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 2, 0, 1, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 0, 1, 2, 2, 1, 0, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 0, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 0, 2, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 2, 1, 2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 2, 2, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 2, 1, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2, 1, 2, 0, 1, 1, 1, 2, 2, 2, 1, 0, 0, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 1, 2, 2, 0, 0, 2, 1, 2, 0, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 2, 1, 1, 2, 2, 0, 0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 2, 1, 2, 1, 1, 2, 0, 0, 2, 2, 2, 1, 0, 1, 0, 0, 2, 1, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 2, 1, 0, 2, 0, 2, 2, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 0, 2, 1, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 1, 0, 2, 2, 1, 2, 0, 2, 0, 2, 0, 2, 2, 1, 1, 1, 0, 2, 2, 1, 0, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 2, 1, 0, 2, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 0, 1, 0, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 2, 0, 1, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 2, 1, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 0, 0, 2, 2, 0, 2, 2, 1, 1, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 0, 0, 0, 2, 1, 1, 1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 0, 1, 1, 0, 0, 1, 2, 2, 2, 1, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 2, 2, 1, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 1, 2, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 0, 0, 2, 0, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 1, 1, 1, 0, 2, 2, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 0, 1, 1, 1, 0, 2, 2, 0, 0, 1, 2, 1, 2, 1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 0, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 1, 2, 0, 2, 0, 2, 0, 1, 0, 2, 1, 2, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 2, 0, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['sentiment']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh          1\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...          2\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...          0\n",
       "3  01082688c6                                        happy bday!          2\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!          2"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>e5f0e6ef4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>416863ce47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>6332da480c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>df1baec676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>469e15c5a8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  sentiment\n",
       "0     f87dea47db          1\n",
       "1     96d74cb729          2\n",
       "2     eee518ae67          0\n",
       "3     01082688c6          2\n",
       "4     33987a8ee5          2\n",
       "...          ...        ...\n",
       "3529  e5f0e6ef4b          0\n",
       "3530  416863ce47          2\n",
       "3531  6332da480c          0\n",
       "3532  df1baec676          2\n",
       "3533  469e15c5a8          2\n",
       "\n",
       "[3534 rows x 2 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1.drop(columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_back(inp):\n",
    "    if(inp==1):\n",
    "        return 'neutral'\n",
    "    elif(inp==2):\n",
    "        return 'positive'\n",
    "    elif(inp==0):\n",
    "        return 'negative'\n",
    "\n",
    "    \n",
    "    \n",
    "train_df1['sentiment']=train_df1.sentiment.apply(convert_back)\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.to_csv(r'C:\\Users\\Siddharth Tripathi\\Desktop\\DataScience_Pranjal\\Kaggle_assessment\\sentiment-analysis-msa-phase-2\\final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
